"""
Test script para verificar que Anthropic funciona correctamente
"""
import asyncio
import os
from dotenv import load_dotenv
from langchain_anthropic import ChatAnthropic
from langchain.prompts import ChatPromptTemplate

load_dotenv()

async def test_anthropic_basic():
    """Test b√°sico de Anthropic con LangChain"""
    print("=" * 60)
    print("TEST 1: Conexi√≥n b√°sica con Anthropic")
    print("=" * 60)
    
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        print("‚ùå ERROR: ANTHROPIC_API_KEY no configurada")
        return False
    
    print(f"‚úÖ API Key encontrada: {api_key[:10]}...")
    
    try:
        # Modelo correcto de Anthropic
        llm = ChatAnthropic(
            model="claude-3-5-sonnet-20241022",
            anthropic_api_key=api_key,
            max_tokens=100,
            temperature=0.7
        )
        print("‚úÖ Cliente ChatAnthropic creado correctamente")
        
        # Test simple
        prompt = ChatPromptTemplate.from_messages([
            ("system", "Eres un asistente √∫til."),
            ("user", "Di 'Hola mundo' en JSON: {{'mensaje': 'tu respuesta'}}")
        ])
        
        chain = prompt | llm
        print("‚úÖ Chain creado con operador |")
        
        response = await chain.ainvoke({})
        print("‚úÖ Respuesta recibida")
        print(f"Tipo de respuesta: {type(response)}")
        print(f"Contenido: {response.content}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå ERROR: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_json_generation():
    """Test de generaci√≥n de JSON"""
    print("\n" + "=" * 60)
    print("TEST 2: Generaci√≥n de JSON")
    print("=" * 60)
    
    api_key = os.getenv("ANTHROPIC_API_KEY")
    
    try:
        llm = ChatAnthropic(
            model="claude-3-5-sonnet-20241022",
            anthropic_api_key=api_key,
            max_tokens=500,
            temperature=0.7
        )
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", "Eres un experto en reclutamiento."),
            ("user", """Genera 3 preguntas para un desarrollador Python.

Retorna √öNICAMENTE un JSON:
[
  {{"pregunta": "texto aqu√≠", "tipo_pregunta": "abierta"}},
  {{"pregunta": "texto aqu√≠", "tipo_pregunta": "si_no"}}
]

No incluyas markdown, solo JSON.""")
        ])
        
        chain = prompt | llm
        response = await chain.ainvoke({})
        
        print("‚úÖ JSON generado:")
        print(response.content)
        
        # Intentar parsear
        import json
        try:
            data = json.loads(response.content.strip())
            print("‚úÖ JSON v√°lido parseado correctamente")
            print(f"N√∫mero de preguntas: {len(data)}")
        except:
            # Intentar limpiar markdown
            text = response.content.strip()
            if text.startswith("```"):
                lines = text.split("\n")
                text = "\n".join(lines[1:-1])
                if text.startswith("json"):
                    text = text[4:]
            data = json.loads(text.strip())
            print("‚úÖ JSON parseado despu√©s de limpiar markdown")
        
        return True
        
    except Exception as e:
        print(f"‚ùå ERROR: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_ia_service():
    """Test del servicio de IA completo"""
    print("\n" + "=" * 60)
    print("TEST 3: Servicio de IA completo")
    print("=" * 60)
    
    try:
        from services.ia_service import ia_service
        
        print("‚úÖ IAService importado correctamente")
        
        # Test generar preguntas
        print("\nGenerando preguntas...")
        preguntas = await ia_service.generar_preguntas_vacante(
            titulo="Desarrollador Python",
            descripcion="Buscamos desarrollador con experiencia en FastAPI",
            habilidades_requeridas=["Python", "FastAPI", "PostgreSQL"],
            experiencia_min=2
        )
        
        print(f"‚úÖ Preguntas generadas: {len(preguntas)}")
        for i, p in enumerate(preguntas, 1):
            print(f"  {i}. {p['pregunta'][:50]}... ({p['tipo_pregunta']})")
        
        # Test analizar CV
        print("\nAnalizando CV...")
        cv_test = """
        Juan P√©rez
        Desarrollador Python con 3 a√±os de experiencia
        Habilidades: Python, FastAPI, Django, PostgreSQL, Docker
        Educaci√≥n: Ingenier√≠a de Sistemas
        """
        
        analisis = await ia_service.analizar_cv(cv_test)
        print(f"‚úÖ CV analizado:")
        print(f"  Habilidades: {analisis.get('habilidades', [])}")
        print(f"  Experiencia: {analisis.get('experiencia_a√±os', 0)} a√±os")
        print(f"  Educaci√≥n: {analisis.get('educacion', 'N/A')}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå ERROR: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """Ejecutar todos los tests"""
    print("\nüöÄ INICIANDO TESTS DE ANTHROPIC + LANGCHAIN\n")
    
    results = []
    
    # Test 1: B√°sico
    results.append(await test_anthropic_basic())
    
    # Test 2: JSON
    results.append(await test_json_generation())
    
    # Test 3: Servicio completo
    results.append(await test_ia_service())
    
    # Resumen
    print("\n" + "=" * 60)
    print("RESUMEN DE TESTS")
    print("=" * 60)
    passed = sum(results)
    total = len(results)
    print(f"‚úÖ Tests exitosos: {passed}/{total}")
    
    if passed == total:
        print("\nüéâ ¬°TODOS LOS TESTS PASARON!")
        print("El servicio de IA est√° funcionando correctamente.")
    else:
        print("\n‚ö†Ô∏è  Algunos tests fallaron. Revisa los errores arriba.")


if __name__ == "__main__":
    asyncio.run(main())
